"""
S3ì— ì´ë¯¸ ì—…ë¡œë“œëœ PDF íŒŒì¼ë“¤ì„ ë²¡í„°í™”í•˜ëŠ” ë°°ì¹˜ ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
    python batch_vectorize_s3_pdfs.py --school-id 1 --category academic

ì˜µì…˜:
    --school-id: í•™êµ ID (í•„ìˆ˜)
    --category: ë¬¸ì„œ ì¹´í…Œê³ ë¦¬ (ì„ íƒ)
    --department: ë‹´ë‹¹ ë¶€ì„œ (ì„ íƒ)
    --prefix: S3 í´ë” ê²½ë¡œ (ì˜ˆ: documents/school_1/)
    --dry-run: ì‹¤ì œ ì²˜ë¦¬ ì—†ì´ ëª©ë¡ë§Œ í™•ì¸
"""

import os
import sys
import argparse
import boto3
from io import BytesIO
from typing import List, Dict, Any
import logging

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, os.path.abspath(os.path.dirname(__file__)))

from app.database.database import SessionLocal
from app.services.document_service import document_service
from app.services.llm_service import llm_service
from app.database import models
from PyPDF2 import PdfReader
from langchain.text_splitter import RecursiveCharacterTextSplitter

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class S3PDFVectorizer:
    """S3ì˜ ê¸°ì¡´ PDFë¥¼ ë²¡í„°í™”í•˜ëŠ” í´ë˜ìŠ¤"""

    def __init__(self, bucket_name: str):
        """
        Args:
            bucket_name: S3 ë²„í‚· ì´ë¦„
        """
        self.bucket_name = bucket_name
        self.s3_client = boto3.client(
            's3',
            region_name=os.getenv("AWS_REGION", "us-west-1")
        )
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            separators=["\n\n", "\n", ". ", "! ", "? ", " ", ""]
        )

    def list_pdfs(self, prefix: str = "") -> List[Dict[str, Any]]:
        """
        S3 ë²„í‚·ì—ì„œ PDF íŒŒì¼ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.

        Args:
            prefix: S3 í´ë” ê²½ë¡œ (ì˜ˆ: "documents/")

        Returns:
            PDF íŒŒì¼ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        logger.info(f"ğŸ“‚ Listing PDFs from s3://{self.bucket_name}/{prefix}")

        pdf_files = []
        paginator = self.s3_client.get_paginator('list_objects_v2')

        for page in paginator.paginate(Bucket=self.bucket_name, Prefix=prefix):
            if 'Contents' not in page:
                continue

            for obj in page['Contents']:
                key = obj['Key']
                if key.lower().endswith('.pdf'):
                    pdf_files.append({
                        'key': key,
                        'size': obj['Size'],
                        'last_modified': obj['LastModified']
                    })

        logger.info(f"âœ… Found {len(pdf_files)} PDF files")
        return pdf_files

    def download_pdf(self, s3_key: str) -> BytesIO:
        """
        S3ì—ì„œ PDF íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.

        Args:
            s3_key: S3 ê°ì²´ í‚¤

        Returns:
            PDF íŒŒì¼ ìŠ¤íŠ¸ë¦¼
        """
        logger.info(f"â¬‡ï¸  Downloading: {s3_key}")

        response = self.s3_client.get_object(Bucket=self.bucket_name, Key=s3_key)
        return BytesIO(response['Body'].read())

    def extract_text_from_pdf(self, pdf_stream: BytesIO) -> str:
        """
        PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.

        Args:
            pdf_stream: PDF íŒŒì¼ ìŠ¤íŠ¸ë¦¼

        Returns:
            ì¶”ì¶œëœ í…ìŠ¤íŠ¸
        """
        reader = PdfReader(pdf_stream)
        text = ""

        for i, page in enumerate(reader.pages):
            page_text = page.extract_text() or ""
            text += f"[í˜ì´ì§€ {i+1}]\n{page_text}\n\n"

        logger.info(f"ğŸ“„ Extracted {len(text)} characters from {len(reader.pages)} pages")
        return text.strip()

    def process_pdf(
        self,
        s3_key: str,
        school_id: int,
        category: str,
        department: str = None,
        db_session = None,
        dry_run: bool = False
    ) -> Dict[str, Any]:
        """
        PDF íŒŒì¼ì„ ì²˜ë¦¬í•˜ì—¬ ë²¡í„°í™”í•©ë‹ˆë‹¤.

        Args:
            s3_key: S3 íŒŒì¼ ê²½ë¡œ
            school_id: í•™êµ ID
            category: ë¬¸ì„œ ì¹´í…Œê³ ë¦¬
            department: ë‹´ë‹¹ ë¶€ì„œ
            db_session: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
            dry_run: Trueë©´ ì‹¤ì œ ì €ì¥í•˜ì§€ ì•ŠìŒ

        Returns:
            ì²˜ë¦¬ ê²°ê³¼
        """
        try:
            # 1. S3ì—ì„œ PDF ë‹¤ìš´ë¡œë“œ
            pdf_stream = self.download_pdf(s3_key)

            # 2. í…ìŠ¤íŠ¸ ì¶”ì¶œ
            text = self.extract_text_from_pdf(pdf_stream)

            if not text or len(text) < 50:
                return {
                    "status": "skipped",
                    "reason": "í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìŒ",
                    "s3_key": s3_key
                }

            # 3. í…ìŠ¤íŠ¸ ì²­í‚¹
            chunks = self.text_splitter.split_text(text)
            chunks = [c.strip() for c in chunks if c.strip() and len(c.strip()) > 50]

            logger.info(f"âœ‚ï¸  Created {len(chunks)} chunks")

            if dry_run:
                return {
                    "status": "dry_run",
                    "s3_key": s3_key,
                    "text_length": len(text),
                    "chunk_count": len(chunks)
                }

            # 4. ì„ë² ë”© ìƒì„±
            embeddings = llm_service.get_embeddings(chunks)

            if not embeddings:
                logger.warning("âš ï¸  ì„ë² ë”© ìƒì„± ì‹¤íŒ¨ - í‚¤ì›Œë“œ ê²€ìƒ‰ë§Œ ì‚¬ìš© ê°€ëŠ¥")
                # ì„ë² ë”© ì—†ì´ë„ ë¬¸ì„œëŠ” ì €ì¥ (í‚¤ì›Œë“œ ê²€ìƒ‰ìš©)
                embeddings = None

            # 5. DBì— ë¬¸ì„œ ë ˆì½”ë“œ ìƒì„±
            filename = s3_key.split('/')[-1]
            s3_url = f"https://{self.bucket_name}.s3.{os.getenv('AWS_REGION', 'us-west-1')}.amazonaws.com/{s3_key}"

            new_document = models.Document(
                school_id=school_id,
                category=category,
                file_name=filename,
                s3_url=s3_url,
                source_url=s3_url,
                department=department
            )

            db_session.add(new_document)
            db_session.commit()
            db_session.refresh(new_document)

            logger.info(f"ğŸ’¾ Document saved with ID: {new_document.id}")

            # 6. ì²­í¬ì™€ ì„ë² ë”© ì €ì¥
            chunk_count = 0
            for i, chunk_text in enumerate(chunks):
                # ì„ë² ë”©ì´ ì—†ìœ¼ë©´ Noneìœ¼ë¡œ ì €ì¥ (í‚¤ì›Œë“œ ê²€ìƒ‰ìš©)
                embedding = embeddings[i] if embeddings else None

                chunk_record = models.DocumentChunk(
                    document_id=new_document.id,
                    chunk_text=chunk_text,
                    embedding=embedding
                )
                db_session.add(chunk_record)
                chunk_count += 1

            db_session.commit()
            logger.info(f"âœ… Saved {chunk_count} chunks")

            return {
                "status": "success",
                "s3_key": s3_key,
                "document_id": new_document.id,
                "text_length": len(text),
                "chunk_count": chunk_count
            }

        except Exception as e:
            logger.error(f"âŒ Error processing {s3_key}: {e}")
            if db_session and 'new_document' in locals():
                db_session.rollback()

            return {
                "status": "error",
                "s3_key": s3_key,
                "error": str(e)
            }


def main():
    parser = argparse.ArgumentParser(description='S3ì˜ ê¸°ì¡´ PDFë¥¼ ë²¡í„°í™”í•©ë‹ˆë‹¤.')
    parser.add_argument('--school-id', type=int, required=True, help='í•™êµ ID')
    parser.add_argument('--category', type=str, default='general', help='ë¬¸ì„œ ì¹´í…Œê³ ë¦¬')
    parser.add_argument('--department', type=str, help='ë‹´ë‹¹ ë¶€ì„œ')
    parser.add_argument('--prefix', type=str, default='documents/', help='S3 í´ë” ê²½ë¡œ')
    parser.add_argument('--dry-run', action='store_true', help='ì‹¤ì œ ì²˜ë¦¬ ì—†ì´ ëª©ë¡ë§Œ í™•ì¸')

    args = parser.parse_args()

    # í™˜ê²½ ë³€ìˆ˜ í™•ì¸
    bucket_name = os.getenv("S3_BUCKET_NAME")
    if not bucket_name:
        logger.error("âŒ S3_BUCKET_NAME í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        sys.exit(1)

    logger.info("=" * 60)
    logger.info("ğŸš€ S3 PDF ë²¡í„°í™” ë°°ì¹˜ ì‘ì—… ì‹œì‘")
    logger.info("=" * 60)
    logger.info(f"ë²„í‚·: {bucket_name}")
    logger.info(f"í•™êµ ID: {args.school_id}")
    logger.info(f"ì¹´í…Œê³ ë¦¬: {args.category}")
    logger.info(f"ê²½ë¡œ: {args.prefix}")
    logger.info(f"Dry Run: {args.dry_run}")
    logger.info("=" * 60)

    # S3 ë²¡í„°ë¼ì´ì € ì´ˆê¸°í™”
    vectorizer = S3PDFVectorizer(bucket_name)

    # PDF ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    pdf_files = vectorizer.list_pdfs(args.prefix)

    if not pdf_files:
        logger.warning("âš ï¸  ì²˜ë¦¬í•  PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜ ìƒì„±
    db = SessionLocal()

    try:
        results = {
            "success": 0,
            "error": 0,
            "skipped": 0,
            "dry_run": 0
        }

        # ê° PDF ì²˜ë¦¬
        for i, pdf_info in enumerate(pdf_files, 1):
            logger.info(f"\n{'='*60}")
            logger.info(f"ğŸ“ Processing [{i}/{len(pdf_files)}]: {pdf_info['key']}")
            logger.info(f"{'='*60}")

            result = vectorizer.process_pdf(
                s3_key=pdf_info['key'],
                school_id=args.school_id,
                category=args.category,
                department=args.department,
                db_session=db,
                dry_run=args.dry_run
            )

            results[result["status"]] += 1

            if result["status"] == "success":
                logger.info(f"âœ… ì„±ê³µ: Document ID {result['document_id']}")
            elif result["status"] == "error":
                logger.error(f"âŒ ì‹¤íŒ¨: {result.get('error')}")
            elif result["status"] == "skipped":
                logger.warning(f"â­ï¸  ê±´ë„ˆëœ€: {result.get('reason')}")

        # ìµœì¢… ê²°ê³¼ ì¶œë ¥
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ“Š ìµœì¢… ê²°ê³¼")
        logger.info("=" * 60)
        logger.info(f"âœ… ì„±ê³µ: {results['success']}")
        logger.info(f"âŒ ì‹¤íŒ¨: {results['error']}")
        logger.info(f"â­ï¸  ê±´ë„ˆëœ€: {results['skipped']}")
        if args.dry_run:
            logger.info(f"ğŸ” Dry Run: {results['dry_run']}")
        logger.info("=" * 60)

    finally:
        db.close()


if __name__ == "__main__":
    main()
